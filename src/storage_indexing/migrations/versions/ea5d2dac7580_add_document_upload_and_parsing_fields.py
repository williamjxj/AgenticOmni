"""Add document upload and parsing fields

Revision ID: ea5d2dac7580
Revises: 05584d5088b8
Create Date: 2026-01-09 22:31:35.928937

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'ea5d2dac7580'
down_revision: Union[str, Sequence[str], None] = '05584d5088b8'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('upload_sessions',
    sa.Column('session_id', sa.Uuid(), nullable=False, comment='Primary key, unique session identifier (UUID)'),
    sa.Column('tenant_id', sa.Integer(), nullable=False, comment='Foreign key to tenants'),
    sa.Column('user_id', sa.Integer(), nullable=False, comment='Foreign key to users'),
    sa.Column('filename', sa.String(length=255), nullable=False, comment='Original filename'),
    sa.Column('mime_type', sa.String(length=100), nullable=False, comment='Detected MIME type'),
    sa.Column('total_size_bytes', sa.BigInteger(), nullable=False, comment='Total file size in bytes'),
    sa.Column('uploaded_size_bytes', sa.BigInteger(), nullable=False, comment='Bytes uploaded so far'),
    sa.Column('chunk_size_bytes', sa.Integer(), nullable=False, comment='Chunk size in bytes (default 5MB)'),
    sa.Column('storage_path', sa.String(length=500), nullable=False, comment='Temporary storage location'),
    sa.Column('status', sa.String(length=50), nullable=False, comment='Session status (active, completed, cancelled, expired)'),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False, comment='Session expiration timestamp (24 hours)'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp'),
    sa.ForeignKeyConstraint(['tenant_id'], ['tenants.tenant_id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.user_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('session_id')
    )
    op.create_index(op.f('ix_upload_sessions_expires_at'), 'upload_sessions', ['expires_at'], unique=False)
    op.create_index(op.f('ix_upload_sessions_status'), 'upload_sessions', ['status'], unique=False)
    op.create_index(op.f('ix_upload_sessions_tenant_id'), 'upload_sessions', ['tenant_id'], unique=False)
    op.create_index(op.f('ix_upload_sessions_user_id'), 'upload_sessions', ['user_id'], unique=False)
    op.add_column('document_chunks', sa.Column('chunk_type', sa.String(length=50), nullable=False, comment='Type of chunk (text, table, list, heading, code)'))
    op.add_column('document_chunks', sa.Column('start_page', sa.Integer(), nullable=True, comment='Starting page number (1-indexed)'))
    op.add_column('document_chunks', sa.Column('end_page', sa.Integer(), nullable=True, comment='Ending page number'))
    op.add_column('document_chunks', sa.Column('token_count', sa.Integer(), nullable=True, comment='Approximate token count for LLM context'))
    op.add_column('document_chunks', sa.Column('parent_heading', sa.Text(), nullable=True, comment='Section heading for context'))
    op.create_index(op.f('ix_document_chunks_chunk_type'), 'document_chunks', ['chunk_type'], unique=False)
    op.add_column('documents', sa.Column('content_hash', sa.String(length=64), nullable=False, comment='SHA-256 hash for duplicate detection'))
    op.add_column('documents', sa.Column('language', sa.String(length=10), nullable=True, comment='Detected document language (ISO 639-1 code)'))
    op.add_column('documents', sa.Column('page_count', sa.Integer(), nullable=True, comment='Number of pages (for PDF/DOCX)'))
    op.add_column('documents', sa.Column('uploaded_by', sa.Integer(), nullable=False, comment='User who uploaded the document'))
    op.add_column('documents', sa.Column('original_filename', sa.String(length=255), nullable=False, comment='Original filename from upload'))
    op.add_column('documents', sa.Column('mime_type', sa.String(length=100), nullable=False, comment='Detected MIME type (e.g., application/pdf)'))
    op.alter_column('documents', 'processing_status',
               existing_type=sa.VARCHAR(length=50),
               comment='Processing status (uploaded, parsing, parsed, failed)',
               existing_comment='Processing status (pending, processing, completed, failed)',
               existing_nullable=False)
    op.create_index(op.f('ix_documents_content_hash'), 'documents', ['content_hash'], unique=False)
    op.create_index(op.f('ix_documents_uploaded_by'), 'documents', ['uploaded_by'], unique=False)
    op.create_foreign_key(None, 'documents', 'users', ['uploaded_by'], ['user_id'], ondelete='SET NULL')
    op.add_column('processing_jobs', sa.Column('progress_percent', sa.Float(), nullable=False, comment='Current progress percentage (0-100)'))
    op.add_column('processing_jobs', sa.Column('estimated_time_remaining', sa.Integer(), nullable=True, comment='Estimated time remaining in seconds'))
    op.add_column('processing_jobs', sa.Column('started_by', sa.Integer(), nullable=True, comment='User who initiated the job'))
    op.create_index(op.f('ix_processing_jobs_started_by'), 'processing_jobs', ['started_by'], unique=False)
    op.create_foreign_key(None, 'processing_jobs', 'users', ['started_by'], ['user_id'], ondelete='SET NULL')
    op.add_column('tenants', sa.Column('storage_quota_bytes', sa.BigInteger(), nullable=False, comment='Maximum storage quota in bytes'))
    op.add_column('tenants', sa.Column('storage_used_bytes', sa.BigInteger(), nullable=False, comment='Current storage usage in bytes'))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('tenants', 'storage_used_bytes')
    op.drop_column('tenants', 'storage_quota_bytes')
    op.drop_constraint(None, 'processing_jobs', type_='foreignkey')
    op.drop_index(op.f('ix_processing_jobs_started_by'), table_name='processing_jobs')
    op.drop_column('processing_jobs', 'started_by')
    op.drop_column('processing_jobs', 'estimated_time_remaining')
    op.drop_column('processing_jobs', 'progress_percent')
    op.drop_constraint(None, 'documents', type_='foreignkey')
    op.drop_index(op.f('ix_documents_uploaded_by'), table_name='documents')
    op.drop_index(op.f('ix_documents_content_hash'), table_name='documents')
    op.alter_column('documents', 'processing_status',
               existing_type=sa.VARCHAR(length=50),
               comment='Processing status (pending, processing, completed, failed)',
               existing_comment='Processing status (uploaded, parsing, parsed, failed)',
               existing_nullable=False)
    op.drop_column('documents', 'mime_type')
    op.drop_column('documents', 'original_filename')
    op.drop_column('documents', 'uploaded_by')
    op.drop_column('documents', 'page_count')
    op.drop_column('documents', 'language')
    op.drop_column('documents', 'content_hash')
    op.drop_index(op.f('ix_document_chunks_chunk_type'), table_name='document_chunks')
    op.drop_column('document_chunks', 'parent_heading')
    op.drop_column('document_chunks', 'token_count')
    op.drop_column('document_chunks', 'end_page')
    op.drop_column('document_chunks', 'start_page')
    op.drop_column('document_chunks', 'chunk_type')
    op.drop_index(op.f('ix_upload_sessions_user_id'), table_name='upload_sessions')
    op.drop_index(op.f('ix_upload_sessions_tenant_id'), table_name='upload_sessions')
    op.drop_index(op.f('ix_upload_sessions_status'), table_name='upload_sessions')
    op.drop_index(op.f('ix_upload_sessions_expires_at'), table_name='upload_sessions')
    op.drop_table('upload_sessions')
    # ### end Alembic commands ###
