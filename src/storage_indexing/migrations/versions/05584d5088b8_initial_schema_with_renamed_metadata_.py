"""Initial schema with renamed metadata fields

Revision ID: 05584d5088b8
Revises:
Create Date: 2026-01-09 17:53:50.020034

"""

from collections.abc import Sequence

import sqlalchemy as sa
from alembic import op
from pgvector.sqlalchemy import Vector

# revision identifiers, used by Alembic.
revision: str = "05584d5088b8"
down_revision: str | Sequence[str] | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "tenants",
        sa.Column(
            "tenant_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique tenant identifier",
        ),
        sa.Column(
            "name", sa.String(length=255), nullable=False, comment="Tenant name (organization name)"
        ),
        sa.Column(
            "domain",
            sa.String(length=255),
            nullable=False,
            comment="Tenant domain slug (unique identifier)",
        ),
        sa.Column(
            "settings", sa.JSON(), nullable=True, comment="Tenant-specific configuration (JSONB)"
        ),
        sa.Column(
            "status",
            sa.String(length=50),
            nullable=False,
            comment="Tenant status (active, suspended, inactive)",
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record creation timestamp",
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record last update timestamp",
        ),
        sa.PrimaryKeyConstraint("tenant_id"),
    )
    op.create_index(op.f("ix_tenants_domain"), "tenants", ["domain"], unique=True)
    op.create_table(
        "documents",
        sa.Column(
            "document_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique document identifier",
        ),
        sa.Column(
            "tenant_id",
            sa.Integer(),
            nullable=False,
            comment="Foreign key to tenants (row-level isolation)",
        ),
        sa.Column("filename", sa.String(length=255), nullable=False, comment="Original filename"),
        sa.Column(
            "file_type",
            sa.String(length=100),
            nullable=False,
            comment="File MIME type or extension",
        ),
        sa.Column("file_size", sa.Integer(), nullable=False, comment="File size in bytes"),
        sa.Column(
            "storage_path",
            sa.String(length=500),
            nullable=False,
            comment="Path to stored file (local or cloud)",
        ),
        sa.Column(
            "processing_status",
            sa.String(length=50),
            nullable=False,
            comment="Processing status (pending, processing, completed, failed)",
        ),
        sa.Column(
            "document_metadata",
            sa.JSON(),
            nullable=True,
            comment="Document-specific metadata (JSONB)",
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record creation timestamp",
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record last update timestamp",
        ),
        sa.ForeignKeyConstraint(["tenant_id"], ["tenants.tenant_id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("document_id"),
    )
    op.create_index(
        op.f("ix_documents_processing_status"), "documents", ["processing_status"], unique=False
    )
    op.create_index(op.f("ix_documents_tenant_id"), "documents", ["tenant_id"], unique=False)
    op.create_table(
        "users",
        sa.Column(
            "user_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique user identifier",
        ),
        sa.Column(
            "tenant_id",
            sa.Integer(),
            nullable=False,
            comment="Foreign key to tenants (row-level isolation)",
        ),
        sa.Column(
            "email",
            sa.String(length=255),
            nullable=False,
            comment="User email address (unique per tenant)",
        ),
        sa.Column(
            "hashed_password",
            sa.String(length=255),
            nullable=False,
            comment="Bcrypt hashed password",
        ),
        sa.Column(
            "role",
            sa.String(length=50),
            nullable=False,
            comment="User role for RBAC (admin, editor, viewer)",
        ),
        sa.Column("full_name", sa.String(length=255), nullable=True, comment="User's full name"),
        sa.Column(
            "last_login", sa.DateTime(timezone=True), nullable=True, comment="Last login timestamp"
        ),
        sa.Column("is_active", sa.Boolean(), nullable=False, comment="Account active status"),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record creation timestamp",
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record last update timestamp",
        ),
        sa.ForeignKeyConstraint(["tenant_id"], ["tenants.tenant_id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("user_id"),
    )
    op.create_index(op.f("ix_users_email"), "users", ["email"], unique=False)
    op.create_index(op.f("ix_users_tenant_id"), "users", ["tenant_id"], unique=False)
    op.create_table(
        "document_chunks",
        sa.Column(
            "chunk_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique chunk identifier",
        ),
        sa.Column("document_id", sa.Integer(), nullable=False, comment="Foreign key to documents"),
        sa.Column("content_text", sa.Text(), nullable=False, comment="Text content of the chunk"),
        sa.Column(
            "embedding_vector",
            Vector(1536),
            nullable=True,
            comment="Vector embedding (1536 dimensions)",
        ),
        sa.Column(
            "chunk_order",
            sa.Integer(),
            nullable=False,
            comment="Order of chunk within document (0-indexed)",
        ),
        sa.Column(
            "chunk_metadata", sa.JSON(), nullable=True, comment="Chunk-specific metadata (JSONB)"
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record creation timestamp",
        ),
        sa.ForeignKeyConstraint(["document_id"], ["documents.document_id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("chunk_id"),
    )
    op.create_index(
        op.f("ix_document_chunks_document_id"), "document_chunks", ["document_id"], unique=False
    )
    op.create_table(
        "permissions",
        sa.Column(
            "permission_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique permission identifier",
        ),
        sa.Column("user_id", sa.Integer(), nullable=False, comment="Foreign key to users"),
        sa.Column(
            "resource_type",
            sa.String(length=50),
            nullable=False,
            comment="Type of resource (document, folder, collection)",
        ),
        sa.Column("resource_id", sa.Integer(), nullable=False, comment="ID of the resource"),
        sa.Column(
            "permission_level",
            sa.String(length=50),
            nullable=False,
            comment="Access level (read, write, admin)",
        ),
        sa.Column(
            "granted_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Timestamp when permission was granted",
        ),
        sa.Column(
            "granted_by", sa.Integer(), nullable=True, comment="User ID who granted the permission"
        ),
        sa.ForeignKeyConstraint(["granted_by"], ["users.user_id"], ondelete="SET NULL"),
        sa.ForeignKeyConstraint(["user_id"], ["users.user_id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("permission_id"),
    )
    op.create_index(op.f("ix_permissions_user_id"), "permissions", ["user_id"], unique=False)
    op.create_table(
        "processing_jobs",
        sa.Column(
            "job_id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Primary key, unique job identifier",
        ),
        sa.Column(
            "document_id",
            sa.Integer(),
            nullable=True,
            comment="Foreign key to documents (nullable for non-document jobs)",
        ),
        sa.Column(
            "tenant_id",
            sa.Integer(),
            nullable=False,
            comment="Foreign key to tenants (row-level isolation)",
        ),
        sa.Column(
            "job_type",
            sa.String(length=100),
            nullable=False,
            comment="Type of job (document_parsing, embedding_generation, etc.)",
        ),
        sa.Column(
            "status",
            sa.String(length=50),
            nullable=False,
            comment="Current job status (pending, processing, completed, failed, cancelled, retrying)",
        ),
        sa.Column("retry_count", sa.Integer(), nullable=False, comment="Number of retry attempts"),
        sa.Column(
            "max_retries", sa.Integer(), nullable=False, comment="Maximum number of retries allowed"
        ),
        sa.Column(
            "started_at", sa.DateTime(timezone=True), nullable=True, comment="Job start timestamp"
        ),
        sa.Column(
            "completed_at",
            sa.DateTime(timezone=True),
            nullable=True,
            comment="Job completion timestamp",
        ),
        sa.Column("error_message", sa.Text(), nullable=True, comment="Error message if job failed"),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            nullable=False,
            comment="Record creation timestamp",
        ),
        sa.ForeignKeyConstraint(["document_id"], ["documents.document_id"], ondelete="CASCADE"),
        sa.ForeignKeyConstraint(["tenant_id"], ["tenants.tenant_id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("job_id"),
    )
    op.create_index(
        op.f("ix_processing_jobs_document_id"), "processing_jobs", ["document_id"], unique=False
    )
    op.create_index(op.f("ix_processing_jobs_status"), "processing_jobs", ["status"], unique=False)
    op.create_index(
        op.f("ix_processing_jobs_tenant_id"), "processing_jobs", ["tenant_id"], unique=False
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_processing_jobs_tenant_id"), table_name="processing_jobs")
    op.drop_index(op.f("ix_processing_jobs_status"), table_name="processing_jobs")
    op.drop_index(op.f("ix_processing_jobs_document_id"), table_name="processing_jobs")
    op.drop_table("processing_jobs")
    op.drop_index(op.f("ix_permissions_user_id"), table_name="permissions")
    op.drop_table("permissions")
    op.drop_index(op.f("ix_document_chunks_document_id"), table_name="document_chunks")
    op.drop_table("document_chunks")
    op.drop_index(op.f("ix_users_tenant_id"), table_name="users")
    op.drop_index(op.f("ix_users_email"), table_name="users")
    op.drop_table("users")
    op.drop_index(op.f("ix_documents_tenant_id"), table_name="documents")
    op.drop_index(op.f("ix_documents_processing_status"), table_name="documents")
    op.drop_table("documents")
    op.drop_index(op.f("ix_tenants_domain"), table_name="tenants")
    op.drop_table("tenants")
    # ### end Alembic commands ###
